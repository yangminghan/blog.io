---
layout: post
title: 决策树和随机森林学习笔记（一）
date: 2018-1-23
categories: blog
tags: [机器学习]
description: 
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# 决策树和随机森林学习笔记

## 信息熵
熵（Entropy）是表示随机变量不确定性的度量。设有随机变量X，则：
$$
P\left ( X=x_{i} \right )=p_{i}\: \: i=1,2,...n
$$
则随机变量X的熵定义为：
$$
H \left(X \right)=-\sum ^{n}_{i=1}p_{i}log(p_{i})
$$

若随机变量X服从两点分布：

X | 0 | 1
---|---|---
P| p |1-p
则X的熵为：
$$
H(X)=-p log_2p-(1-p)log_2p
$$

## 条件熵

设有随机变量（X,Y）联合分布概率为:
$$
P(X=x_i,Y=y_i)=p_{i j}\quad i=1,2...n\ j=1,2,...m
$$

**条件熵**$$H（Y|X）$$表示在已知随机变量X的条件下，随机变量Y的不确定性。随机变量X给定的条件下随机变量Y 的条件熵（conditional entropy）$$H（Y|X）$$，定义为X给定条件下Y的条件概率分布的熵对X的数学期望：
$$
H(Y|X)=\sum_{i=1}^{n}p_i H(Y|X=x_i ) \quad p_i=P(X=x_i),\ i=1,2,..n
$$

当熵和条件熵中的概率由数据估计（特别是极大似然估计）得到时，所对应的熵与条件熵分别称为**经验熵**（empirical entropy）和**经验条件熵**（empirical conditional entropy）。
## 信息增益
## 信息增益比
## 基尼系数

- 这个是无序列表
- 这个是无序列表
1. 这个是有序列表
2. 这个是有序列表

















