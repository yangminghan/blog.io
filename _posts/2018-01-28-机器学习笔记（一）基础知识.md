---
layout: post
title: 机器学习笔记（一） 基础知识
date: 2018-1-28
categories: blog
tags: [机器学习]
description: 
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>
# 机器学习笔记（一） 基础知识
通常将机器学习算法定义为这样一类算法：对于某给定的**任务T**，在合理的性能度量**方案P**的前提下，某计算机程序可以自主学习**任务T**的**经验E**;随着提供合适、优质、大量的**经验E**，该程序对于**任务T**的性能逐步提高。简单的来讲， 即随着任务的不断执行，经验的累积会带来模型性能的提升。  
那么机器学习算法有三个重要的对象：**任务T(Task)，经验E(Experience)，性能P(Performance)**。与此对应的是统计学习方法的三要素：**模型(model),策略(strategy)和算法(algorithm)**。   
方法= 模型 + 策略 + 算法  
## 实现机器学习方法的步骤如下：  
1.得到一个有限的**训练数据集合**；  
2.确定包含**所有可能的模型**的假设空间，即学习模型的集合；  
3.确定模型选择的准则，即**学习的策略**；  
4.实现求解的最优模型的算法，即**学习的算法**；  
5.通过学习方法选择**最优模型**；  
6.利用学习的最优模型对**新数据**进行预测或分析。  

## 机器学习的三要素：
### 1 模型
首先要明确这样一个概念，在机器学习中，输入，输出，参数往往是多维向量，这里就引入了**假设空间**(hypothesis space) 的概念。
模型的假设空间用$$F$$表示，包含所有可能的条件概率分布或决策函数，**例如**，假设，决策函数为线性函数，那么模型的假设空间就是所有这些线性函数构成的函数集合。  
模型的假设空间可以定义为决策函数的集合：
```math
F = \{f|Y=f_{\theta}(X),\theta \in \mathbb{R}^{n}\}
```
其中，X和Y是定义在**输入空间X**和**输出空间Y**上的变量，这时，F通常是由一个参数向量决定的函数族，参数向量$\theta$取值于n维欧式空间R^n，称为参数空间。  

假设空间也可以定义为条件概率的集合：
```math
F = \{P|P_{\theta}(Y|X),\theta \in \mathbb{R}^{n}\}
```
其中，X和Y是定义在输入空间X和输出空间Y上的随机变量，这时F通常是有一个参数变量$\theta$决定的条件概率分布族。
### 2 策略
有了模型的假设空间，机器学习接着需要考虑的是，按照什么样的**准则**，**学习或者选择**==最优的模型==。机器学习的目标就在于在模型的假设空间中选择最优的模型。  
首先，介绍**损失函数**与**风险函数**的概念。损失函数度量模型一次预测的好坏，风险函数度量平均意义下模型预测的好坏。  
#### 损失函数
监督学习的问题是在模型的假设空间F中选取最优的模型f作为决策函数，对于给定的输入X，有f(x)给出相应的预测$Y\hat$,输出的预测值可能与真实值Y一直，也可能不一致，因此，我们使用损失函数(loss function)或代价函数（cost function）来度量预测错误的程度。损失函数时f（x）和Y的非负实值函数，记做$L(Y,f(x))$。  
机器学习常用的损失函数有以下几种：
```math
L(Y,f(x))=
```


## 1 算法分类
根据不同的任务T，我认为可以将机器学习算法分为，监督学习(supervised learning),无监督学习(unsupervised learning),半监督学习(semi-supervised learning),强化学习(reinforcement learning)。
监督学习(supervised learning)的任务是学习一个模型，使模型能够对任意给定的输入，对其相应的输出做一个很好的做一个很好的预测。
有监督学习与无监督学习
## 2 求解方法
梯度下降算法
牛顿法
拟牛顿法
## 3 数据处理


