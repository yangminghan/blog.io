---
layout: post
title: 机器学习笔记———基础知识(2)
date: 2018-1-30
categories: blog
tags: [机器学习]
description: 
---
<script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"></script>

# 机器学习笔记  基础知识(2)

## 1 训练误差与测试误差 

&emsp;&emsp;机器学习的目的是让学习到的模型不仅对已知数据而且对于未知数据都能有很好的预测能力。当损失函数给定时，我们使用基于**损失函数**的模型**训练误差**(training error)和**测试误差**(test error)来评估模型。  
&emsp;&emsp;假设学习到的模型是 

$$
Y =\hat{f}(X)
$$

&emsp;&emsp;那么，训练误差是模型关于训练数据集的平均损失：

$$
R_{emp}(\hat{f}) = \frac{1}{N}\sum^{N}_{i=1}L(y_i,\hat{f}(x_i))
$$

&emsp;&emsp;其中N为训练样本容量。  
&emsp;&emsp;测试误差是模型关于测试数据集的平均损失：

$$
e_{test} = \frac{1}{N_{test}}\sum^{N_{test}}_{i=1}L(y_{i},\hat{f}(x_i))
$$

其中$$N_{test}$$为测试数据集样本量。
## 2 过拟合与模型选择  

&emsp;&emsp;当假设空间中含有不同复杂度（例如不同的参数个数）的模型时，我们就要面临**模型选择**(model selection)的问题。我们希望可以得到这样一个模型：如果在假设空间中存在“真”模型，那么所选择的模型应该逼近真模型，具体地，我们希望我们得到的模型与真模型的**参数**个数相同，所选择的模型的**参数向量**与怎么新的参数向量相近。  
&emsp;&emsp;但是，如果我们一味追求提高对训练数据的预测能力，所选择的模型的复杂度往往比真模型更高，这种现象称为**过拟合**(over fitting)。  
&emsp;&emsp;假设给定一个训练数据集：

$$
T = \left\{ (x_1,y_1),(x_2,y_2),...(x_n,y_n)\right\}
$$
&emsp;&emsp;其中，$$x_i\in\mathrm{R}$$ 
是输入x的观测值，$$y_i\in \mathrm{R}$$是相应的输出y的观测值，$$i=1,2,...N $$。我们使用多项式函数拟合数据，则存在最高阶数为N-1的多项式函数可以穿过所有样本点，理由是n维范德蒙行列式是正定的。

## 3 泛化能力   
&emsp;&emsp;学习方法的泛化能力(generalization ability)是指由该学习方法学习到的模型对未知数据的预测能力，是学习方法本质上重要的性质。
## 4 正则化、交叉验证与特征归一化
#### 正则化
&emsp;&emsp;模型选择的典型方法是正则化(regularization)。正则化是结构风险最小化策略的实现，是在经验风险上增加一个正则化项(regularier)或者罚项(penalty term)。正则化项一般是模型复杂度的单调递增函数，模型越复杂，正则化值就越大。比如，正则化项可以是模型函数参数向量的**范式**。
正则化一般具有如下形式：

$$
min_{f \in{\mathcal{F}}} = \frac{1}{N}\sum^{N}_{i=1}L(y_i,f(x_i))+\lambda J(f)
$$

其中，第一项是经验风险，第二项是正则化项,$$\lambda \geqslant 0$$为调整两者之间关系的系数。
正则化项可以取不同的形式。例如：在回归问题中，损失函数为平方损失，正则化项可以是参数向量的$$L_2$$范式。  

$$
L(W)=\frac{1}{N}\sum^{N}_{i=1}(y_i-f(x_i;w))^2+\frac{\lambda}{2}\lVert w\rVert^{2}  
$$
  
L1正则化项：  
$$  
\lVert \mathrm{x}\rVert_1 = \sum_{i=1}^{n}\lvert x_i\rvert
$$  
L2正则化项：  
$$  
\lVert \mathrm{x}\rVert_2 = \sqrt{\sum_{i=1}^{n} x_i^2}
$$  
Lq正则化项：  
$$  
\lVert \mathrm{x}\rVert_q = (\sum_{i=1}^{n} x_i^p)^\frac{1}{p}  
$$  
&emsp;&emsp;正则化符合奥卡姆剃刀原理(Occam's razor)。奥卡姆剃刀原理应用于模型选择时变为如下想法：在所有可能选择的模型中，能够很好解释已知数据并且十分简单的模型才是最好的模型，也就是应该选择的模型。
#### 交叉验证
&emsp;&emsp;我们通常使用交叉验证方法选择合适的超参数，如果给定样本数据充足，进行模型选择的一种简单方法是将数据集切分为三个部分，分别是训练集(training set),验证集(validation set)和测试集(test set)。训练集用来训练模型，验证集用于选择模型超参，测试集用于最终对于学习方法进行评估。  
&emsp;&emsp;应用最多的是S折交叉验证，方法如下：首先随机地将已给数据切分成S个互不相交的大小相同的子集，然后利用S-1个子集的数据训练模型，利用余下子集测试模型，将这一过程对可能的S中选择重复进行；最后选出S次评测中平均测试误差最小的模型。  



在Python中，交叉验证很好实现，sklearn.model_selection可以实现

```python

```
####归一化
####one-hot编码